---
title: 'UC Berkeley CS189 Assignment 4 (Part 1)'
description: 'CS189 Assignment4 Notes'
publishDate: '2026-2-8'
tags: ['CS189']
# heroImage: { src: './thumbnail.jpg', alt: '作业封面图片' }
# heroImage: {}
language: '中文'
draft: true
---

import { Aside } from 'astro-pure/user'

# CS189 Assignment 4

## 项目描述

从这个项目起基本上告别小打小闹了, 我们要用`PyTorch`来搭建一些较为复杂的模型, 比如说CNN, Transformer, Bert. 关于`PyTorch`的API用法我不会做太多解释, 和CS336笔记中一样, 我会着重说明这些线性变换的尺寸和方式, 我觉得这才是真正理解模型的重要点

学习目标如下:


-- 用PyTorch搭建自己的神经网络
-- 理解并实现自定义的Datasets, DataLoaders和训练循环
-- 学习如何复现论文中的模型架构
-- 理解ResNet架构
-- 用PyTorch实现Transformer
-- 理解Transformer的原理


## Problem 1a

用PyTorch写一个CNN类, 非常简单, 只要照着他给出的卷积核的尺寸往里填就行了

```python
class CNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # TODO: Instantiate the layers your CNN will have!
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=7, stride=2, padding=1)
        self.linear = nn.Linear(in_features=16*54*54, out_features=num_classes)
        # Optional: You can also define your ReLU layers here if you'd like
        # Otherwise, if you decide to use F.relu you can just remove these lines
        self.relu1 = nn.ReLU()
        self.relu2 = nn.ReLU()

    def forward(self, x):
        # TODO: 1. Pass the input through the first conv layer
        conv1_out = self.conv1(x)

        # TODO: 2. Apply ReLU
        relu1_out = self.relu1(conv1_out)

        # TODO: 3. Pass to the 2nd conv layer
        conv2_out = self.conv2(relu1_out)

        # TODO: 4. Apply ReLU
        relu2_out = self.relu2(conv2_out)

        # TODO: 5. Flatten before linear layer
        flat = relu2_out.view(relu2_out.size(0), -1)

        # TODO: 6. Pass to linear layer
        out = self.linear(flat)

        return out
```

假设我们传入的尺寸为`(1, 224 ,224 ,3)`, 具体含义是一个batch有一张图片, 一个图片有三个图层(channel), 图片的长和宽都是224, 不过我觉得没有必要对高维张量去进行具体的想象什么维度代表什么, 因为超过三维的东西就很难想得明白, 只要记住这个二维卷积核肯定是对倒数第一和第二的维度做变换就行了

### conv1上的尺寸变换

conv1的尺寸为:
```python
self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)
```

先考虑对最后两维的变化, 卷积核的尺寸为3, 步长为2, 填充为1, 所以输出尺寸为:
```
Gauss((224 + 1 * 2 - 3) / 2 + 1) = 112
```

其中Gauss()是向下取整函数, 又因为卷积核指定了`out_channels = 16`, 所以输出尺寸为`(1, 16, 112, 112)`

再解释一下这个输出通道的变化, 如图所示:

```
输入图片(3个图层)           每个输出通道的卷积核
┌─────────────┐
│   224 * 224   │ ──▶ 3 * 3 矩阵(处理R层)──┐
│   (R通道)   │                         │
├─────────────┤                         │
│   224 * 224   │ ──▶ 3 * 3 矩阵(处理G)）──┼──▶ 求和 ──▶ 输出1个通道
│   (G通道)   │                         │
├─────────────┤                         │
│   224 * 224   │ ──▶ 3 * 3 矩阵(处理B层)──┘
│   (B通道)   │
└─────────────┘
```

对于每个输出通道(1/16), 都有3个3*3的卷积核, 每个卷积核去处理输入当中的一个通道, 所以总共有16 * 3个卷积核, 每个的尺寸是3 * 3

也就是说, 输出通道变多的意思是我们有很多的卷积核分别在原图的不同层次上学习特征, 并且每次只输出一个通道

### conv2上的尺寸变换

conv2的尺寸为:
```python
self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=7, stride=2, padding=1)
```

先考虑对最后两维的变化, 卷积核的尺寸为7, 步长为2, 填充为1, 所以输出尺寸为:
```
Gauss((112 + 1 * 2 - 7) / 2 + 1) = 54
```

所以输出尺寸为`(1, 16, 54, 54)`

### Linear上的尺寸变换

linear的尺寸为:
```python
self.linear = nn.Linear(in_features=16*54*54, out_features=num_classes)
```

输入尺寸为`(1, 16, 54, 54)`, 所以输出尺寸为`(1, num_classes)`

这里其实有两个步骤, 首先去做一个flatten操作, 把`(1, 16, 54, 54)`变成`(1, 16 * 54 * 54)`, 然后再去做一个线性变换, 把`(1, 16 * 54 * 54)`变成`(1, num_classes)`, 注意这一步总是可行的, 因为一个高维的东西总是可以把他的每个元素拿出来然后flatten到一维


### 检查输出尺寸

运行他的检查代码, 确保我们的实现是正确的

```python
x = torch.rand((1, 3, 224, 224))  # 1 image, 3 RGB channels, 224 x 224 pixels
print(f"Shape of input: {x.shape}")

res = CNN(num_classes=10)
out = res(x)
print(f"Shape of output: {out.shape}")
assert out.shape == torch.Size([1, 10]), f"Expected output shape (1, 10), but got {out.shape}"
```

```
Shape of input: torch.Size([1, 3, 224, 224])
Shape of output: torch.Size([1, 10])
```